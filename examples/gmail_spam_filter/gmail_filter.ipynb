{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Your Own Gmail Spam Filter - Any LLM You Choose\n",
    "\n",
    "Are you annoyed with constantly receiving spam or sales emails? You're not alone. Despite Gmail's spam filter \n",
    "catching over 50 spam emails daily, we, as startup founders, still found our inboxes flooded with 20+ unwanted \n",
    "emails each day.\n",
    "\n",
    "Last weekend, we decided to write our own personalized spam filter script to filter out unwanted emails from our \n",
    "inbox. There are some online posts showing how to use GPT to fitler email, but still hard to config and \n",
    "only support OpenAI. Hence, we decide to share our solution, which are\n",
    "- **Quick to set up** (under an hour),\n",
    "- **Cost-effective** (less than $1 per month),\n",
    "- **Compatible with various LLM models** (including OpenAI, Google Gemini, Anthropic, Mistral-7B, LLaMA, and more).\n",
    "\n",
    "In this example, we will show you how to choose an LLM and build your own spam gmails filter via \n",
    "[Uniflow](https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering), \n",
    "an open-source and LLM agonistic library for data cleaning.\n",
    "\n",
    "\n",
    "<div style=\"border-left: 4px solid lightblue; background-color: lightblue; color: white; padding: 10px 20px; margin: 20px 0;\">\n",
    "\n",
    "### Before running the code\n",
    "\n",
    "1. [Estimated: 5 min] You will need to set up the `uniflow` conda environment to run this notebook by following this [instruction](https://github.com/CambioML/uniflow/tree/main#installation).\n",
    "\n",
    "2. [Estimated: 5 min] You will need a valid api key to run the code (either OpenAI or Google Gemini):\n",
    "    - [Get Google API key](https://ai.google.dev/tutorials/setup). \n",
    "    - [Get OpenAI API key](https://platform.openai.com/api-keys). \n",
    " \n",
    "    Once you have the key, set it as the environment variable (either `OPENAI_API_KEY` or `GOOGLE_API_KEY`) within a `.env` file in the root directory of this repository. For more details, see this [instruction](https://github.com/CambioML/uniflow/tree/main#api-keys).\n",
    "\n",
    "</div>\n",
    "\n",
    "### Import the libraries and update system path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the dependencies in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tiktoken uniflow==0.0.27\n",
    "!pip install -q --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goldpiggy/anaconda3/envs/uniflow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uniflow import Context\n",
    "from uniflow.flow.client import ExtractClient\n",
    "from uniflow.flow.config import ExtractGmailConfig\n",
    "from uniflow.flow.client import TransformClient\n",
    "from uniflow.flow.config  import TransformGmailSpamConfig\n",
    "from uniflow.op.model.model_config  import GoogleModelConfig, OpenAIModelConfig\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize an `ExtractClient` with `ExtractGmailConfig`\n",
    "\n",
    "There are two steps to build an Gmail spam filter: extract the email content and then classify whether it's spam. Let's start with the extract step.\n",
    "\n",
    "<div style=\"border-left: 4px solid lightblue; background-color: lightblue; color: white; padding: 10px 20px; margin: 20px 0;\">\n",
    "\n",
    "### Set credentials\n",
    "\n",
    "[Estimated: 10 min] You will need to setup and download `credentials.json` following google workspace [instructions](https://developers.google.com/gmail/api/quickstart/python). \n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "With the credentials, you can initialize an `ExtractClient` to extract your email text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_client = ExtractClient(\n",
    "    ExtractGmailConfig(\n",
    "        credentials_path=\"credentials.json\",\n",
    "        token_path=\"token.json\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once run the above cell, there will be a pop up URL to authorize the Gmail log in from your own gmail spam filter. \n",
    "\n",
    "Click `Allow`:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./gmail-spam-filter-login.png\" alt=\"Alternate Text\" width=\"50%\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `extract_client` to extract the latest unread email body and snippet (maximum 7 emails). Estimated running time: 10-20 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.34s/it]\n"
     ]
    }
   ],
   "source": [
    "extract_data = extract_client.run([{}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize an `TransformClient` with `TransformGmailSpamConfig`\n",
    "\n",
    "Now you have retrieved the email's text using the `Extract` client. Now we define a `Transform` client to classify whether an given email is spam or not. The default `TransformGmailSpamConfig` contains instructions and few shots prompt regarding spam classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment and uncomment to try both openai and google models\n",
    "transform_client = TransformClient(\n",
    "    TransformGmailSpamConfig(\n",
    "        flow_name=\"TransformOpenAIFlow\",\n",
    "        model_config=OpenAIModelConfig(),\n",
    "        # flow_name=\"TransformGoogleFlow\",\n",
    "        # model_config=GoogleModelConfig()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `transform_client` will take the extract result from `extract_client` and further transform it with output contains classification label. Let's print out the default `TransformGmailSpamConfig` to see the default prompts and model configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformGmailSpamConfig(flow_name='TransformOpenAIFlow',\n",
      "                         model_config=OpenAIModelConfig(model_name='gpt-3.5-turbo-1106',\n",
      "                                                        model_server='OpenAIModelServer',\n",
      "                                                        num_call=1,\n",
      "                                                        temperature=0.9,\n",
      "                                                        response_format={'type': 'text'},\n",
      "                                                        num_thread=1,\n",
      "                                                        batch_size=1),\n",
      "                         num_thread=1,\n",
      "                         prompt_template=PromptTemplate(instruction='You are a highly intelligent AI trained to identify spam emails. Is this email a spam email?. Follow the format of the few shot examples below to include explain and answer in the response for the given email. You answer should be either Yes or No.', few_shot_prompt=[Context(email=\"Subject: Meeting Rescheduled Hi Team, We need to reschedule this week's meeting to Thursday at 3 PM due to a conflict. Please update your calendars and let me know if you have any issues with this new time. Best, Alex\", explain=\"This email is non-spam as it directly relates to the recipient's interests, contains no suspicious links or requests, and uses a personalized, professional tone.\", answer='no'), Context(email=\"Subject: Congratulations! You've Won! Dear Valued Customer, You've been selected to win a free iPhone! Click here to claim your prize now! Offer expires in 24 hours. No purchase necessary. Best, Prize Notification Team\", explain='This email is spam due to its unsolicited offer, use of urgency to provoke immediate action, inclusion of a suspicious link, and lack of personalization, which are classic signs of spam.', answer='yes')]),\n",
      "                         auto_split_long_text=False)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(transform_client._config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than throwing the email body and snippet to the `transform_client`, we clean up and only use the first 5000 characters to avoid time out.\n",
    "\n",
    "Let's take a look of the first email extracted text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context(email=b'View this post on the web at https://www.datagravity.dev/p/150b-of-annual-capex-the-trends-in\\r\\n\\r\\nMeta recently announced acquiring over 600K GPUs in 2024 [ https://substack.com/redirect/e7a530a0-c07c-44cd-b92d-a9aa6a7caa89?j=eyJ1IjoiMzBwdXhjIn0.D3udPa-oMTfcKnoniYWOWKKkcZ3T4hfaoUhanbZZxGs ] with plans for $37B of total capital expenditure investment. The announcement triggered a wave of analysis speculating which hardware vendors would benefit from this data center investment. \\r\\nToday, we look at the CAPEX of all 6 of the trillion dollar tech companies \\xe2\\x80\\x94 which are Apple, Microsoft, Nvidia, Amazon, Google and Meta. The majority of this total CAPEX involves data centers, for a mix of internal and customer usage \\xe2\\x80\\x94 though there are big strategic differences by company which reflect unique business models and goals. We calculated these metrics by downloading the cash flow statements of each company and compiling the CAPEX data into one sheet (below). \\r\\nData Gravity is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.\\r\\nSource file, compiled by Data Gravity using Pitchbook of cash flow statements of each hyperscaler (GOOG, AAPL, MSFT, AMZN, META, NVDA):\\r\\nHyperscaler CAPEX Trends:\\r\\nOver the past 10 years, these hyperscalers have allocated ~$871B of total capital expenditures, growing 6X from $24.8B in 2013 to over $150B last year \\xe2\\x80\\x94 representing  an annual CAGR of over 20%. There are no signs of slowing down with the past 5 years also averaging a 20% CAGR as companies invest ahead of AI. Surprisingly, there are huge variances between each of the companies. We discuss below:\\r\\nGraph of each hyperscaler, with highest at bottom and lowest at top:\\r\\nTable of each hyperscaler, sorted low to high:\\r\\nSummary: Hyperscaler CAPEX\\r\\nApple was the #1 allocator of CAPEX in 2013, though has fallen dramatically to now being the 5th after hardly any additional net new expenditure. NVIDIA surprisingly has essentially no CAPEX and far below its peers \\xe2\\x80\\x94 outsourcing manufacturing to TSMC [ https://substack.com/redirect/ca809904-64eb-4190-9b92-bd1a6d3e3fcd?j=eyJ1IjoiMzBwdXhjIn0.D3udPa-oMTfcKnoniYWOWKKkcZ3T4hfaoUhanbZZxGs ] allows for a capital light business model. \\r\\nSomewhat surprisingly, the Big 3 Cloud Vendors are the 3 largest CAPEX investors \\xe2\\x80\\x94 with Amazon leading the charge at 33%, Google following at 22%, and Microsoft in 3rd at 19%. Meta closely follows the Big 3 Clouds and has grown to nearly Microsoft\\xe2\\x80\\x99s size at 18% of total CAPEX \\xe2\\x80\\x94 it is an exceptional customer for third-party firms to consider and drives over $1B/year of revenue to Arista and much more to NVIDIA. Notably, there are huge allocation strategy differences in CAPEX between the hyperscalers \\xe2\\x80\\x94 some are known for procuring mostly third-party hardware versus developing in-house. We discuss each below. \\r\\nAmazon: Annual CAPEX ($B)\\r\\nAmazon began 2013 as the 4th largest allocator of CAPEX with about $3.4B of annual spend across its AWS and commerce businesses\\r\\nToday, Amazon is the largest allocator of CAPEX with $48.2B of annual CAPEX and 33% of the hyperscaler total allocation \\r\\nAmazon grew CAPEX the 2nd most (only behind Meta in expansion) by a multiple of 14X and a 10Y CAGR of 30%\\r\\nAmazon is known for allocating to data centers, fulfillment centers and delivery infrastructure\\r\\nAmazon\\xe2\\x80\\x99s CAPEX allocation strategy is known for being internal versus procuring from other vendors \\xe2\\x80\\x94 developing its own chips and data center hardware, though having a more adversarial relationship with third-parties it also relies on like NVIDIA\\r\\nThe internal focused capital expenditure strategy make Amazon a notoriously stingy customer and menace to third-party startups who sell to its competitors\\r\\nGoogle: Annual CAPEX ($B)\\r\\nGoogle began 2013 as the 2nd largest allocator of CAPEX with about $7.4B of annual spend \\xe2\\x80\\x94 for its search and video infrastructure as well as nascent Google Cloud business; it also had high internal demand\\r\\nToday, Alphabet is the 2nd largest allocator of CAPEX with $32.3B of annual CAPEX and 22% of the hyperscaler total CAPEX allocation \\r\\nAlphabet grew CAPEX by a multiple of 4.4X and a 10Y CAGR of 16%\\r\\nGoogle is known for allocating to Cloud data centers, internal research and development with projects like DeepMind, video infrastructure for YouTube, real estate and workplace environment (where it is far in excess of peers)\\r\\nAlphabet\\xe2\\x80\\x99s CAPEX allocation strategy is known for being a mix of internal and external \\xe2\\x80\\x94 developing its own TPU chips with Broadcom and traditional data center hardware, having a neutral relationship with NVIDIA and other third-party vendors. \\r\\nAlphabet also works on \\xe2\\x80\\x9cOther Bets\\xe2\\x80\\x9d including self-driving cars, Nest and more \\xe2\\x80\\x94 some of which are hard to determine if on the balance sheet or not due to clever financial engineering.\\r\\nMicrosoft: Annual CAPEX ($B)\\r\\nMicrosoft began 2013 as the 3rd largest allocator of CAPEX with about $4.3B of annual spend \\xe2\\x80\\x94 for its c')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_transform = []\n",
    "for d in extract_data[0]['output'][0]:\n",
    "    if d['body']:\n",
    "        data_to_transform.append(Context(email=d['body'][:5000]))\n",
    "    else:\n",
    "        data_to_transform.append(Context(email=d['snippet'][:5000]))\n",
    "data_to_transform[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's the time to run the `transform_client` to classify whether an email is spam or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "transform_output = transform_client.run(data_to_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update corresponding email with label\n",
    "\n",
    "Finally, we can interface with the Gmail API to sort emails with precision, categorizing them as either spam or not with the help of an AI Email Filter. By setting the stage with essential imports and establishing secure OAuth 2.0 credentials, we ensure a seamless connection that grants us the power to modify a user's Gmail according to our needs, specifically under the gmail.modify scope. \n",
    "\n",
    "The heart of our operation lies in a meticulously crafted loop, where we evaluate each email's spam status through an AI's lens and assign the correct label, either marking it as spam or confirming its legitimacy. This process leverages the Gmail API's messages.modify method, seamlessly updating each email's label based on our AI filter's discerning judgment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email 18e199f305038665 is spam: False\n",
      "Email 18e19935d9217e9d is spam: True\n",
      "Email 18e197cf17c6bcde is spam: False\n",
      "Email 18e196121dc03ef4 is spam: True\n",
      "Email 18e1937489ff5f21 is spam: True\n",
      "Email 18e18fb5375cfc71 is spam: False\n",
      "Email 18e163b01309eb98 is spam: False\n"
     ]
    }
   ],
   "source": [
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "SPAM_LABEL = \"Spam Email (AI Email Filter)\"\n",
    "NON_SPAM_LABEL = \"Email (AI Email Filter)\"\n",
    "\n",
    "SCOPES = [\"https://www.googleapis.com/auth/gmail.modify\"]\n",
    "creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "service = build(\"gmail\", \"v1\", credentials=creds)\n",
    "\n",
    "\n",
    "def get_label_id(service, label_name):\n",
    "    labels = service.users().labels().list(userId='me').execute().get('labels', [])\n",
    "    for label in labels:\n",
    "        if label['name'] == label_name:\n",
    "            return label['id']\n",
    "    return None\n",
    "\n",
    "SPAM_LABEL_ID = get_label_id(service, SPAM_LABEL)\n",
    "NON_SPAM_LABEL_ID = get_label_id(service, NON_SPAM_LABEL)\n",
    "\n",
    "for e, t in zip(extract_data[0]['output'][0], transform_output):\n",
    "    # true if spam, false if not\n",
    "    is_spam = \"yes\" in t['output'][0]['response'][0].lower()\n",
    "    print(f\"Email {e['email_id']} is spam: {is_spam}\")\n",
    "    email_id = e['email_id']\n",
    "    label_id = SPAM_LABEL_ID if is_spam else NON_SPAM_LABEL_ID\n",
    "    service.users().messages().modify(userId='me', id=e['email_id'], body={'addLabelIds': [label_id], 'removeLabelIds': []}).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, your email has been auto-classified. Go to your Gmail and search for `label:spam-email--ai-email-filter- `:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./gmail-spam-filter-final-results.png\" alt=\"Alternate Text\" width=\"100%\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the notebook\n",
    "\n",
    "Check more Uniflow use cases in the [example folder](https://github.com/CambioML/uniflow/tree/main/example/model#examples)!\n",
    "\n",
    "<a href=\"https://www.cambioml.com/\" title=\"Title\">\n",
    "    <img src=\"../image/cambioml_logo_large.png\" style=\"height: 100px; display: block; margin-left: auto; margin-right: auto;\"/>\n",
    "</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
